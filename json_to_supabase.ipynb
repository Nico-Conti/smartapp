{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2147791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: test.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob \n",
    "import sys # Import sys to allow for graceful exit on errors\n",
    "import regex\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "INPUT_FILE = 'uomo_catalog/blazers.json'\n",
    "OUTPUT_FILE = 'test.json'\n",
    "\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    new_products = json.load(f)\n",
    "\n",
    "\n",
    "for product in new_products:\n",
    "    \n",
    "    # 1. Image Link Extraction (Existing Logic)\n",
    "    images_list = product.get('images', [])\n",
    "\n",
    "    if isinstance(images_list, list) and len(images_list) >= 2:\n",
    "        product['image_link'] = images_list[-2]\n",
    "    elif isinstance(images_list, list) and len(images_list) == 1:\n",
    "        product['image_link'] = images_list[0]\n",
    "    else:\n",
    "        product['image_link'] = None\n",
    "        print(\"Warning: No images found for product.\")\n",
    "        print(product)\n",
    "\n",
    "    # 2. Robust ID Extraction (The new, sound proof logic)\n",
    "    url: Optional[str] = product.get('url')\n",
    "\n",
    "    if url:\n",
    "        # Use the raw string prefix 'r' to correctly handle backslashes\n",
    "        # The pattern looks for a literal dot, then one or more digits (\\d+), \n",
    "        # followed by a literal dot and 'html'. We capture the digits.\n",
    "        match = regex.search(r'\\.(\\d+)\\.html', url)\n",
    "        \n",
    "        # *** THIS IS THE CRUCIAL CHECK ***\n",
    "        if match:\n",
    "            product_id = match.group(1)\n",
    "            product['id'] = product_id\n",
    "        else:\n",
    "            # If no match, print an error and mark the record\n",
    "            print(f\"Warning: Failed to extract product ID from URL: {url}\")\n",
    "            product['id'] = None # Assign None or another placeholder\n",
    "            products_skipped_count += 1\n",
    "    else:\n",
    "        print(\"Warning: Product record is missing 'url' field.\")\n",
    "        product['id'] = None\n",
    "        products_skipped_count += 1\n",
    "\n",
    "\n",
    "# --- Write the Combined Data ---\n",
    "# The output JSON will be one large array of all product objects\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    # Use indent=4 for a human-readable, pretty-printed output\n",
    "    json.dump(new_products, f, indent=4) \n",
    "    \n",
    "\n",
    "print(f\"File saved to: {OUTPUT_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26553055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total products processed: 35\n"
     ]
    }
   ],
   "source": [
    "cpunt = 0\n",
    "for product in new_products:\n",
    "    cpunt += 1\n",
    "\n",
    "print(f\"Total products processed: {cpunt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61ab64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch, requests\n",
    "from io import BytesIO\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"patrickjohncyh/fashion-clip\")\n",
    "proc  = CLIPProcessor.from_pretrained(\"patrickjohncyh/fashion-clip\")\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def load_img(url):\n",
    "    img = Image.open(BytesIO(requests.get(url, timeout=20).content)).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "def clip_embed(images=None, texts=None):\n",
    "    inputs = proc(text=texts, images=images, return_tensors=\"pt\", padding=True, max_length=77,truncation=True)\n",
    "    with torch.no_grad():\n",
    "        out = model(**{k: v.to(device) for k,v in inputs.items()})\n",
    "    img = out.image_embeds if images is not None else None\n",
    "    txt = out.text_embeds  if texts is not None else None\n",
    "    if img is not None: img = torch.nn.functional.normalize(img, dim=-1)\n",
    "    if txt is not None: txt = torch.nn.functional.normalize(txt, dim=-1)\n",
    "    return img, txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99ea8b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating text embeddings for all records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 35/35 [00:23<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings generated for 35 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Assume Image and clip_embed are defined/imported elsewhere\n",
    "\n",
    "# Create a dummy image to satisfy the model's requirements\n",
    "dummy_image = Image.new('RGB', (224, 224), color='white')\n",
    "\n",
    "print(\"\\nGenerating text embeddings for all records...\")\n",
    "for i in tqdm(range(len(new_products)), desc=\"Generating Embeddings\"):\n",
    "    record = new_products[i]\n",
    "    \n",
    "    # --- Option 1: Embedding the description (No change needed here for 'pattern') ---\n",
    "    if 'schema_description' in record and record['schema_description']: # Added check for value\n",
    "        description = record['schema_description']\n",
    "        # NOTE: Using the 'embedding' column for description as per your table schema\n",
    "        _, txt_emb = clip_embed(images=[dummy_image], texts=[description])\n",
    "        record['embedding'] = txt_emb[0].cpu().numpy().tolist()\n",
    "        # print(f\"Record ID {record['id']}: Description embedding generated.\") # Uncomment for detailed logs\n",
    "    \n",
    "    # --- Option 2: Generating the Detailed Embedding (Focus on this) ---\n",
    "    # We will build a list of non-null/non-empty fields and join them.\n",
    "    if 'schema_description' in record and record['schema_description']: # Check if description exists before generating detailed embedding\n",
    "        # print(f\"Record ID {record['id']}: generating detailed embedding.\") # Uncomment for detailed logs\n",
    "        \n",
    "        # 1. Collect all relevant text parts into a list\n",
    "        details_parts = []\n",
    "        \n",
    "        # Safely get and append fields if they are not None/empty\n",
    "        # Check 1: Title\n",
    "        if record.get('title'):\n",
    "            details_parts.append(record['title'])\n",
    "            \n",
    "        # Check 2: Category\n",
    "        if record.get('category'):\n",
    "            details_parts.append(record['category'])\n",
    "            \n",
    "        # Check 3: Role\n",
    "        if record.get('role'):\n",
    "            details_parts.append(record['role'])\n",
    "            \n",
    "        # Check 4: Color\n",
    "        if record.get('schema_color'):\n",
    "            details_parts.append(record['schema_color'])\n",
    "            \n",
    "        # Check 5: ***The Pattern Field***\n",
    "        if record.get('pattern'):\n",
    "            details_parts.append(record['pattern']) # This is now safely included only if it exists\n",
    "            \n",
    "        # 2. Join the parts with a space to create the final text\n",
    "        details = \" \".join(details_parts).strip()\n",
    "        \n",
    "        if details:\n",
    "            # Generate embeddings for the combined details\n",
    "            # NOTE: Using the 'detail_embedding' column as per your table schema\n",
    "            _, txt_emb = clip_embed(images=[dummy_image], texts=[details])\n",
    "   \n",
    "            record['detail_embedding'] = txt_emb[0].cpu().numpy().tolist()\n",
    "\n",
    "    if 'image_link' in record and record['image_link']:\n",
    "        image = load_img(record['image_link'])\n",
    "        img_emb, _ = clip_embed(images=[image], texts=[\"\"])\n",
    "        record['img_embedding'] = img_emb[0].cpu().numpy().tolist()\n",
    "\n",
    "print(f\"✅ Embeddings generated for {len(new_products)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4b5f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supabase client initialized for table: product_data\n",
      "\n",
      "Starting upsert operation into 'product_data'...\n",
      "Filtering 35 records against the schema...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering Records: 100%|██████████| 35/35 [00:00<00:00, 126770.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered down to 35 valid records for upsert.\n",
      "✅ Upsert successful! Processed 35 record(s).\n"
     ]
    }
   ],
   "source": [
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# Assuming other necessary imports like 'Image' and 'clip_embed' are still available\n",
    "\n",
    "# --- Configuration (Your setup) ---\n",
    "load_dotenv()\n",
    "SUPABASE_URL = os.environ.get(\"SUPABASE_URL\")\n",
    "SUPABASE_SECRET_KEY = os.environ.get(\"SUPABASE_SECRET_KEY\") \n",
    "TABLE_NAME = \"product_data\"          \n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_SECRET_KEY)\n",
    "print(f\"✅ Supabase client initialized for table: {TABLE_NAME}\")\n",
    "\n",
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ALLOWED_COLUMNS = [\n",
    "    \"id\", \"title\", \"url\", \"schema_description\", \"material\", \"brand\", \n",
    "    \"main_category\", \"role\", \"schema_color\", \"category\", \"audience\", \n",
    "    \"price\", \"embedding\", \"detail_embedding\", \"image_link\", \"img_embedding\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nStarting upsert operation into '{TABLE_NAME}'...\")\n",
    "\n",
    "\n",
    "# --- FILTERING STEP ---\n",
    "filtered_products = []\n",
    "\n",
    "print(f\"Filtering {len(new_products)} records against the schema...\")\n",
    "for record in tqdm(new_products, desc=\"Filtering Records\"):\n",
    "    \n",
    "    # Create a new dictionary containing only the allowed keys\n",
    "    filtered_record = {\n",
    "        key: value for key, value in record.items() if key in ALLOWED_COLUMNS\n",
    "    }\n",
    "    \n",
    "    # Ensure the Primary Key is present before appending\n",
    "    if \"id\" in filtered_record:\n",
    "        filtered_products.append(filtered_record)\n",
    "    else:\n",
    "        print(f\"Skipping record due to missing primary key 'id': {record.get('title', 'Unknown Title')}\")\n",
    "\n",
    "print(f\"Filtered down to {len(filtered_products)} valid records for upsert.\")\n",
    "# print(f\"filtered products sample: {filtered_products[:1]}\")  # Print a sample for verification\n",
    "# --- UPSERT STEP ---\n",
    "try:\n",
    "    response = supabase.table(TABLE_NAME).upsert(filtered_products).execute()\n",
    "    \n",
    "    if response.data:\n",
    "        print(f\"✅ Upsert successful! Processed {len(response.data)} record(s).\")\n",
    "    else:\n",
    "        print(\"⚠️ Upsert returned no data. Check for potential RLS policies or other issues.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Upsert failed due to a database error. Error: {e}\")\n",
    "\n",
    "# # Example of calling the function with your list:\n",
    "# # upload_products_to_supabase(new_products, TABLE_NAME, supabase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
